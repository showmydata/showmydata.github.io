---
layout: post
title: "2022春-人工智能-第11讲"
categories: 
  - Courses
tags:
  - 课程学习
  - 人工智能
last_modified_at: 2022-03-29T21:00:52+08:00
---

#### 不确定性推理

> 建立在不确定性知识和证据基础上的推理，泛指除确定性推理外的其它各种推理问题

##### 为什么采用不确定性推理

- 所需知识不完备、不精确
- 所需知识描述模糊
- 多种原因导致同一结论
- 解题方案不唯一

- 初始证据和知识均不确定，结论不确定但合理

##### 不确定性推理的基本问题

- 不确定性的表示
  - 知识不确定性
    - 概率：[0, 1]，0接近于假，1接近于真
    - 可信度：[-1, 1]，大于0接近于真，小于0接近于假
    - 隶属度：[0, 1]，越接近于0隶属度越低，反之越高
  - 证据不确定性
    - 概率、可信度、模糊集
- 不确定性的匹配
  - 不确定的前提条件与不确定的事实匹配
  - 设计一个计算相似程度的算法，给出相似的限度
  - 相似度落在规定限度（阈值）内为匹配，否则为不匹配
- 组合证据不确定性的计算
  - 证据的组合方式：析取、合取
  - 基于基本证据的最大/最小方法、概率方法和有界方法
- 不确定性的更新
  - 根据不同推理方法
  - 把当前结论及其不确定性作为新的结论放入综合数据库，依次传递，直到得出最终结论
- 不确定性结论的合成

##### 不确定性推理类型

- 模型方法
  - 数值方法
    - 概率统计方法：绝对概率方法、贝叶斯方法、证据理论方法、HMM方法、可信度方法
    - 模糊推理方法
    - 粗糙集方法
  - 非数值方法：发生率计算
- 控制方法
  - 相关性制导回溯、机缘控制、启发式搜索

#### 可信度推理

- C-F（Certainty Factor）模型

- 知识不确定性表示

  - 产生式规则表示：`IF E THEN H (CF(H, E))`

  - $CF(H, E)$：可信度因子，反映前提条件与结论的联系强度，[-1, 1]

  - 信任增长度$MB(Measure\,Belief,MB)$

    - $$
      MB(H,E)=
      \left\{
      \begin{array}{**lr**}
      1 & P(H)=1\\
      \frac{P(H|E)-P(H)}{1-P(H)} & P(H|E)\ge P(H) \\
      0 & P(H|E)<P(H)
      \end{array}
      \right.
      $$

  - 不信任增长度$MD(Measure\, Disbelief,MD)$

    - $$
      MD(H,E)=
      \left\{
      \begin{array}{**lr**}
      1 & P(H)=0\\
      \frac{min\{P(H|E),P(H)\}-P(H)}{-P(H)} & 否则 
      \end{array}
      \right.
      $$

  - $CF(H, E) = MB(H, E) - MD(H,E)$

    - $$
      CF(H,E)=
      \left\{
      \begin{array}{**lr**}
      \frac{P(H|E)-P(H)}{1-P(H)} & P(H|E) \gt P(H)\\
      0 & P(H|E) = P(H) \\
      \frac{P(H)-P(H|E)}{P(H)} & P(H|E)\lt P(H) \\
      \end{array}
      \right.
      $$

- 证据不确定性的表示

  - $CF(E)$：范围[-1, 1]
    - 无关：$CF(E)=0$
    - [-1, 0)：负相关
    - (0, 1]：正相关

- 组合证据：

  - 合取、析取、非

- 不确定性的更新：

  - $CF(H)=CF(H,E)\times max\{0,CF(E)\}$
    - $CF(E)\lt 0$时，则$CF(H)=0$
    - $CF(E)=1$时，则$CF(H)=CF(H,E)$

- 不确定性知识的合成：组合计算

  - 分别对每一条知识求出$CF(H)

    - $CF_1(H)=CF(H,E_1)\times max\{0,CF(E_1)\}$
    - $CF_2(H)=CF(H,E_2)\times max\{0,CF(E_2)\}$

  - 求出$E_1$和$E_2$对$H$的综合影响所形成的可信度$CF_{1,2}(H)$

    - $$
      CF(H,E)=
      \left\{
      \begin{array}{**lr**}
      CF_1(H)+CF_2(H)-CF_1(H)CF_2(H) & 若CF_1(H)\ge 0, CF_2(H)\ge 0\\
      CF_1(H)+CF_2(H)+CF_1(H)CF_2(H) & 若CF_1(H)\lt 0, CF_2(H)\lt 0\\
      \frac{CF_1(H)+CF_2(H)}{1-min\{|CF_1(H)|,|CF_2(H)|\}} & 若CF_1(H)与CF_2(H)异号\\
      \end{array}
      \right.
      $$


#### 主观Bayes推理

> 基本思想：由于证据E的出现，使得P(H)变为P(H|E)
>
> 主观Bayes方法，就是研究利用证据E，将先验概率P(H)更新为后验概率P(H|E)

- Bayes公式

  - 全概率公式：$P(B)=\Sigma_{i=1}^{n}P(A_i)\times P(B|A_i)$，$A_i$与$A_j(i\ne j)$互不相容
  - Bayes公式：$P(A_k|B)=\frac{P(A_K,B)}{P(B)}=\frac{P(A_k)P(B|A_K)}{\Sigma_{i=1}^{n}P(A_i)P(B|A_i)}$
  - 概率推理方法：IF E THEN H   P(H|E)

- 主观Bayes区别

  - 引入了（LS，LN）
  - IF A THEN  (LS, LN)  B
  - LS体现了规则成立的充分性
  - LN体现了规则成立的必要性
  - 既考虑时间A的出现对结果B的支持，又考虑了A的不出现对B的影响

- 知识不确定性的表示

  - `IF E THEN (LS, LN) H`
    - 充分性度量$LS=\frac{P(E|H)}{P(E|\neg H)}$
    - 必要性度量$LN=\frac{P(\neg E|H)}{P(\neg E|\neg H)}=\frac{1-P(E|H)}{1-P(E|\neg H)}$

  - 几率$O(X)=\frac{P(X)}{1-P(X)}=\frac{P(X)}{P(\neg X)}$，$P(X)=\frac{O(x)}{1+O(x)}$
    - $O(H|E)=LS\times O(H)$
    - $O(H|\neg E)=LN\times O(H)$
    - $P(H|E)=\frac{O(H|E)}{1+O(H|E)}$
    - 根据上述式子可以判断LS、LN的影响
  - 由于$E$和$\neg E$不会同时支持或同时排斥H，因此只有以下三种情况
    - $LS\gt 1,LN\lt1$：
      - $P(H|E)\gt P(H)\gt P(H|\neg E)$
      - 证据E的存在增加了对H的信任度，E不存在减少对H的信任度
    - $LS=LN=1$：
      - $P(H|E)=P(H)=P(H|\neg E)$
      - 证据E的存在与否对假设H不产生影响
    - $LS\lt 1,LN \gt 1$：
      - $P(H|E)\lt P(H) \lt P(H|\neg E)$
      - 证据E的存在减少了对H的主观信任度，而E不存在则增加H的信任度

- 组合证据

  - 合取min，析取max，非

- 不确定性的更新

  - 根据证据E的概率$P(E)$及LS，LN的值，把H的先验概率$P(H)$，更新为后验概率$P(H|E)$或$P(H|\neg E)$

  - 证据E肯定为假：$P(H|E)=\frac{LS\times P(H)}{(LS-1)\times P(H) +1}$

  - 证据E肯定为真：$P(H|\neg E) = \frac{LN\times P(H)}{(LN-1)\times P(H)+1}$

  - 证据E不确定：杜达公式

    - S是对证据E的观察

    - $P(H|S)=P(H|E)\times P(E|S)+P(H|\neg E)\times P(\neg E|S)$

      - 分为四种情况

      - $P(E|S)=1,P(\neg E|S)=1$

        - $P(H|S)=P(H|E)=\frac{LS \times P(H)}{(LS-1)\times P(H)+1}$

      - $P(E|S)=0,P(\neg E|S)=1$

        - $P(H|S)=P(H|\neg E)=\frac{LN\times P(H)}{(LN-1)\times P(H)+1}$

      - $P(E|S)=P(E),E与S无关$

        - $P(H|S)=P(H|E)\times P(E)+P(H|\neg E)\times P(\neg E)=P(H)$

      - $P(E|S)$为其它值：分段线性插值计算

        - $$
          P(H|S)=
          \left\{
          \begin{array}{**lr**}
          P(H|\neg E)+\frac{P(H)-P(H|\neg E)}{P(E)}\times P(E|S) & 0\le P(E|S) \lt P(E)\\
          P(H) + \frac{P(H|E)-P(H)}{1-P(E)}\times [P(E|S)-P(E)] & P(E)\le P(E|S)\le 1 \\
          \end{array}
          \right.
          $$

- 不确定性结论的合成

  - $O(H|S_1,S_2,...,S_n)=\frac{O(H|S_1)}{O(H)}\times\frac{O(H|S_2)}{O(H)}\times ... \times \frac{O(H|S_n)}{O(H)}\times O(H)$

  - $P(H|E)=\frac{P(H|E)}{P(\neg H|E)+P(H|E)}=\frac{O(H|E)}{1+O(H|E)}$

