---
layout: post
title: "2022春-人工智能-第14讲"
categories: 
  - Courses
tags:
  - 课程学习
  - 人工智能
last_modified_at: 2022-04-12T21:00:52+08:00
---

### 机器学习

#### 学习和机器学习的概念

- 学习
  - 有特定目的的知识获取和能力增长过程
- 机器学习
  - 让机器从数据中学习知识（自动获取知识）

#### 机器学习的分类

- 按学习策略
  - 记忆学习、传授学习、演绎学习、归纳学习
  - 归纳学习又可分为示例学习、观察发现学习等
- 按学习方式
  - 监督学习
    - 数据有标签，一般为回归或分类等任务
  - 无监督学习
    - 数据无标签，一般为聚类或若干降维任务
  - 强化学习
    - 序列数据决策学习，一般为从环境交互中学习
  - 半监督学习
    - 一半有标签，一半无标签

#### 监督学习

- 三要素
  - 标注数据：标识了类别信息的数据
  - 学习模型：如何学习得到映射模型
  - 损失函数：对学习结果进行度量

- 监督学习的学习模型
  - 生成模型和判别模型
  - 判别模型
    - 直接学习判别函数或者条件概率分布
    - 典型判别模型包括回归模型、决策模型、神经网络、支持向量机和集成模型
  - 生成模型
    - 学习联合概率分布P(X，Y)
    - 典型方法为贝叶斯方法、隐马尔可夫链
    - 学的更多，但更难求取

- 损失函数
  - 常用损失函数
    - 0-1损失函数
    - 平方损失函数
    - 绝对损失函数
    - 对数损失函数/对数似然损失函数
    - 等等
  - 经验风险与期望风险
    - 训练集：经验风险
    - 测试集：期望风险
  - 过学习与欠学习
    - 过拟合：经验风险小，期望风险大
    - 欠拟合：经验风险大，期望风险大
  - 结构风险最小化
    - 为了防止过拟合，在经验风险上加上标识模型复杂度的正则化项或惩罚项
    - 在最小化经验风险与降低模型复杂度之间寻找平衡

#### 线性回归

- 参数学习
  - y=ax+b
  - 求a，b两个参数
  - 损失函数是残差平方和

#### 决策树学习

- 介绍
  - 由节点和边构成的用来描述分类过程的层次数据结构
  - 常用算法ID3、C4.5、C5.0和随机森林
  - 学习过程是一个构造决策树的过程

- ID3算法

  - 以整个样本集为根节点，以信息增益最大为原则，选择条件属性进行扩展，逐步构造出决策树的过程

  - 构造过程

    - 从根节点开始，计算所有可能的属性（特征）的信息增益，选择信息增益最大的属性（特征）作为节点的划分特征
    - 由该属性（特征）的不同取值建立子节点
    - 对子节点递归1-2步，构建决策树
    - 直到没有特征可以选择或类别完全相同为止，得到最终的决策树

  - 信息熵和信息增益

    - 信息熵：对信息源整体不确定性的度量

      - $Entropy(S)=H(s)=-\Sigma^k_{i=1}P_ilogP_i$

    - 信息增益：两个信息量之间的差的度量，描述的是信息的确定性

      - $$
        Gain(S,A)=Entropy(S)-\Sigma^r_{i=1}\frac{|S_i|}{|S|}Entropy(S_i) \\
        = Entropy(S)-Entropy(S|x_i)\\
        =H(S) - H(S|x_i)
        $$

#### 支持向量机（SVM）

- 线性可分与最优分类超平面
  - 求解最优分类超平面
- 非线性可分与核函数
  - 利用核函数映射到高维空间，使其线性可分

#### 集成学习

- 两种方式
  - 同质集成（狭义集成学习）
  - 异质集成（广义集成学习）
- Boosting方法
  - 为每个训练样本平均分配初始权重，并训练出弱学习器1
  - 通过提高错误率高得训练样本的权重，降低错误率低的训练样本的权重，得到训练样本的新的权重分布，并在该权重分布上训练出弱学习器2
  - 重复1-2步，直到到达最大迭代轮数
  - 将训练出的弱学习器合成到一起，形成最终的强学习器
- Bagging方法
  - 从初始训练集中使用可重采样的随机抽样方法产生出本轮的训练子集，利用选定的弱学习算法训练出本轮迭代的弱学习器
  - 重复1，直到到达最大迭代轮数
  - 将这些弱学习器合成到一起，形成最终的强学习器
- 弱学习器的合成方法
  - 投票法
  - 代数合成法
    - 平均法
    - 加权平均法



